{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection\n",
    "\n",
    "## Racing Profile\n",
    "\n",
    "Thinking about all the features that would go into a single observation. \n",
    "Observation unit: Driver\n",
    "Dependent variable: Grand Prix finishing position or Podium\n",
    "\n",
    "Independent variables:\n",
    "\n",
    "    * Features from Practice 1-3 and Qualifying Sessions (for each session (x4))\n",
    "\n",
    "        * Min/Max/Avg lap times\n",
    "        * Number of stints (stint_number max)\n",
    "        * Sum of # of practice laps\n",
    "        * Summary stats for minimum lap\n",
    "            * max brake, min/max/avg rpm, max/avg throttle, min/max/avg speed\n",
    "        * Avg Pit duration\n",
    "        * Number of Pits\n",
    "        * Weather\n",
    "            * rain, avg temps, avg wind speed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: import\n",
    "from urllib.request import urlopen\n",
    "from urllib.error import URLError, HTTPError\n",
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime\n",
    "import time\n",
    "import signal\n",
    "\n",
    "query_base = \"https://api.openf1.org/v1/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meeting Query \n",
    "\n",
    "Obtain the list of race weekends, or meetings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 meeting_name  \\\n",
      "0          Pre-Season Testing   \n",
      "1          Bahrain Grand Prix   \n",
      "2    Saudi Arabian Grand Prix   \n",
      "3       Australian Grand Prix   \n",
      "4       Azerbaijan Grand Prix   \n",
      "5            Miami Grand Prix   \n",
      "6           Monaco Grand Prix   \n",
      "7          Spanish Grand Prix   \n",
      "8         Canadian Grand Prix   \n",
      "9         Austrian Grand Prix   \n",
      "10         British Grand Prix   \n",
      "11       Hungarian Grand Prix   \n",
      "12         Belgian Grand Prix   \n",
      "13           Dutch Grand Prix   \n",
      "14         Italian Grand Prix   \n",
      "15       Singapore Grand Prix   \n",
      "16        Japanese Grand Prix   \n",
      "17           Qatar Grand Prix   \n",
      "18   United States Grand Prix   \n",
      "19     Mexico City Grand Prix   \n",
      "20       São Paulo Grand Prix   \n",
      "21       Las Vegas Grand Prix   \n",
      "22       Abu Dhabi Grand Prix   \n",
      "23         Bahrain Grand Prix   \n",
      "24   Saudi Arabian Grand Prix   \n",
      "25      Australian Grand Prix   \n",
      "26        Japanese Grand Prix   \n",
      "27         Chinese Grand Prix   \n",
      "28           Miami Grand Prix   \n",
      "29  Emilia Romagna Grand Prix   \n",
      "30          Monaco Grand Prix   \n",
      "31        Canadian Grand Prix   \n",
      "32         Spanish Grand Prix   \n",
      "33        Austrian Grand Prix   \n",
      "34         British Grand Prix   \n",
      "35       Hungarian Grand Prix   \n",
      "36         Belgian Grand Prix   \n",
      "37           Dutch Grand Prix   \n",
      "38         Italian Grand Prix   \n",
      "39      Azerbaijan Grand Prix   \n",
      "40       Singapore Grand Prix   \n",
      "41   United States Grand Prix   \n",
      "42     Mexico City Grand Prix   \n",
      "43       São Paulo Grand Prix   \n",
      "44       Las Vegas Grand Prix   \n",
      "45           Qatar Grand Prix   \n",
      "46       Abu Dhabi Grand Prix   \n",
      "47         Pre-Season Testing   \n",
      "48      Australian Grand Prix   \n",
      "49         Chinese Grand Prix   \n",
      "50        Japanese Grand Prix   \n",
      "\n",
      "                                meeting_official_name           location  \\\n",
      "0            FORMULA 1 ARAMCO PRE-SEASON TESTING 2023             Sakhir   \n",
      "1          FORMULA 1 GULF AIR BAHRAIN GRAND PRIX 2023             Sakhir   \n",
      "2         FORMULA 1 STC SAUDI ARABIAN GRAND PRIX 2023             Jeddah   \n",
      "3          FORMULA 1 ROLEX AUSTRALIAN GRAND PRIX 2023          Melbourne   \n",
      "4                FORMULA 1 AZERBAIJAN GRAND PRIX 2023               Baku   \n",
      "5          FORMULA 1 CRYPTO.COM MIAMI GRAND PRIX 2023              Miami   \n",
      "6                 FORMULA 1 GRAND PRIX DE MONACO 2023             Monaco   \n",
      "7            FORMULA 1 AWS GRAN PREMIO DE ESPAÑA 2023          Barcelona   \n",
      "8         FORMULA 1 PIRELLI GRAND PRIX DU CANADA 2023           Montréal   \n",
      "9   FORMULA 1 ROLEX GROSSER PREIS VON ÖSTERREICH 2023          Spielberg   \n",
      "10           FORMULA 1 ARAMCO BRITISH GRAND PRIX 2023        Silverstone   \n",
      "11  FORMULA 1 QATAR AIRWAYS HUNGARIAN GRAND PRIX 2023           Budapest   \n",
      "12      FORMULA 1 MSC CRUISES BELGIAN GRAND PRIX 2023  Spa-Francorchamps   \n",
      "13           FORMULA 1 HEINEKEN DUTCH GRAND PRIX 2023          Zandvoort   \n",
      "14        FORMULA 1 PIRELLI GRAN PREMIO D’ITALIA 2023              Monza   \n",
      "15  FORMULA 1 SINGAPORE AIRLINES SINGAPORE GRAND P...         Marina Bay   \n",
      "16          FORMULA 1 LENOVO JAPANESE GRAND PRIX 2023             Suzuka   \n",
      "17      FORMULA 1 QATAR AIRWAYS QATAR GRAND PRIX 2023             Lusail   \n",
      "18     FORMULA 1 LENOVO UNITED STATES GRAND PRIX 2023             Austin   \n",
      "19  FORMULA 1 GRAN PREMIO DE LA CIUDAD DE MÉXICO 2023        Mexico City   \n",
      "20    FORMULA 1 ROLEX GRANDE PRÊMIO DE SÃO PAULO 2023          São Paulo   \n",
      "21  FORMULA 1 HEINEKEN SILVER LAS VEGAS GRAND PRIX...          Las Vegas   \n",
      "22  FORMULA 1 ETIHAD AIRWAYS ABU DHABI GRAND PRIX ...         Yas Island   \n",
      "23         FORMULA 1 GULF AIR BAHRAIN GRAND PRIX 2024             Sakhir   \n",
      "24        FORMULA 1 STC SAUDI ARABIAN GRAND PRIX 2024             Jeddah   \n",
      "25         FORMULA 1 ROLEX AUSTRALIAN GRAND PRIX 2024          Melbourne   \n",
      "26     FORMULA 1 MSC CRUISES JAPANESE GRAND PRIX 2024             Suzuka   \n",
      "27           FORMULA 1 LENOVO CHINESE GRAND PRIX 2024           Shanghai   \n",
      "28         FORMULA 1 CRYPTO.COM MIAMI GRAND PRIX 2024              Miami   \n",
      "29  FORMULA 1 MSC CRUISES GRAN PREMIO DEL MADE IN ...              Imola   \n",
      "30                FORMULA 1 GRAND PRIX DE MONACO 2024             Monaco   \n",
      "31            FORMULA 1 AWS GRAND PRIX DU CANADA 2024           Montréal   \n",
      "32        FORMULA 1 ARAMCO GRAN PREMIO DE ESPAÑA 2024          Barcelona   \n",
      "33   FORMULA 1 QATAR AIRWAYS AUSTRIAN GRAND PRIX 2024          Spielberg   \n",
      "34    FORMULA 1 QATAR AIRWAYS BRITISH GRAND PRIX 2024        Silverstone   \n",
      "35                FORMULA 1 HUNGARIAN GRAND PRIX 2024           Budapest   \n",
      "36            FORMULA 1 ROLEX BELGIAN GRAND PRIX 2024  Spa-Francorchamps   \n",
      "37           FORMULA 1 HEINEKEN DUTCH GRAND PRIX 2024          Zandvoort   \n",
      "38        FORMULA 1 PIRELLI GRAN PREMIO D’ITALIA 2024              Monza   \n",
      "39  FORMULA 1 QATAR AIRWAYS AZERBAIJAN GRAND PRIX ...               Baku   \n",
      "40  FORMULA 1 SINGAPORE AIRLINES SINGAPORE GRAND P...         Marina Bay   \n",
      "41    FORMULA 1 PIRELLI UNITED STATES GRAND PRIX 2024             Austin   \n",
      "42  FORMULA 1 GRAN PREMIO DE LA CIUDAD DE MÉXICO 2024        Mexico City   \n",
      "43   FORMULA 1 LENOVO GRANDE PRÊMIO DE SÃO PAULO 2024          São Paulo   \n",
      "44  FORMULA 1 HEINEKEN SILVER LAS VEGAS GRAND PRIX...          Las Vegas   \n",
      "45      FORMULA 1 QATAR AIRWAYS QATAR GRAND PRIX 2024             Lusail   \n",
      "46  FORMULA 1 ETIHAD AIRWAYS ABU DHABI GRAND PRIX ...         Yas Island   \n",
      "47           FORMULA 1 ARAMCO PRE-SEASON TESTING 2025             Sakhir   \n",
      "48  FORMULA 1 LOUIS VUITTON AUSTRALIAN GRAND PRIX ...          Melbourne   \n",
      "49         FORMULA 1 HEINEKEN CHINESE GRAND PRIX 2025           Shanghai   \n",
      "50          FORMULA 1 LENOVO JAPANESE GRAND PRIX 2025             Suzuka   \n",
      "\n",
      "    country_key country_code          country_name  circuit_key  \\\n",
      "0            36          BRN               Bahrain           63   \n",
      "1            36          BRN               Bahrain           63   \n",
      "2           153          KSA          Saudi Arabia          149   \n",
      "3             5          AUS             Australia           10   \n",
      "4            30          AZE            Azerbaijan          144   \n",
      "5            19          USA         United States          151   \n",
      "6           114          MON                Monaco           22   \n",
      "7             1          ESP                 Spain           15   \n",
      "8            46          CAN                Canada           23   \n",
      "9            17          AUT               Austria           19   \n",
      "10            2          GBR         Great Britain            2   \n",
      "11           14          HUN               Hungary            4   \n",
      "12           16          BEL               Belgium            7   \n",
      "13          133          NED           Netherlands           55   \n",
      "14           13          ITA                 Italy           39   \n",
      "15          157          SGP             Singapore           61   \n",
      "16            4          JPN                 Japan           46   \n",
      "17          149          QAT                 Qatar          150   \n",
      "18           19          USA         United States            9   \n",
      "19            8          MEX                Mexico           65   \n",
      "20           10          BRA                Brazil           14   \n",
      "21           19          USA         United States          152   \n",
      "22           21          UAE  United Arab Emirates           70   \n",
      "23           36          BRN               Bahrain           63   \n",
      "24          153          KSA          Saudi Arabia          149   \n",
      "25            5          AUS             Australia           10   \n",
      "26            4          JPN                 Japan           46   \n",
      "27           53          CHN                 China           49   \n",
      "28           19          USA         United States          151   \n",
      "29           13          ITA                 Italy            6   \n",
      "30          114          MON                Monaco           22   \n",
      "31           46          CAN                Canada           23   \n",
      "32            1          ESP                 Spain           15   \n",
      "33           17          AUT               Austria           19   \n",
      "34            2          GBR         Great Britain            2   \n",
      "35           14          HUN               Hungary            4   \n",
      "36           16          BEL               Belgium            7   \n",
      "37          133          NED           Netherlands           55   \n",
      "38           13          ITA                 Italy           39   \n",
      "39           30          AZE            Azerbaijan          144   \n",
      "40          157          SGP             Singapore           61   \n",
      "41           19          USA         United States            9   \n",
      "42            8          MEX                Mexico           65   \n",
      "43           10          BRA                Brazil           14   \n",
      "44           19          USA         United States          152   \n",
      "45          149          QAT                 Qatar          150   \n",
      "46           21          UAE  United Arab Emirates           70   \n",
      "47           36          BRN               Bahrain           63   \n",
      "48            5          AUS             Australia           10   \n",
      "49           53          CHN                 China           49   \n",
      "50            4          JPN                 Japan           46   \n",
      "\n",
      "    circuit_short_name                 date_start gmt_offset  meeting_key  \\\n",
      "0               Sakhir  2023-02-23T07:00:00+00:00   03:00:00         1140   \n",
      "1               Sakhir  2023-03-03T11:30:00+00:00   03:00:00         1141   \n",
      "2               Jeddah  2023-03-17T13:30:00+00:00   03:00:00         1142   \n",
      "3            Melbourne  2023-03-31T01:30:00+00:00   11:00:00         1143   \n",
      "4                 Baku  2023-04-28T09:30:00+00:00   04:00:00         1207   \n",
      "5                Miami  2023-05-05T18:00:00+00:00  -04:00:00         1208   \n",
      "6          Monte Carlo  2023-05-26T11:30:00+00:00   02:00:00         1210   \n",
      "7            Catalunya  2023-06-02T11:30:00+00:00   02:00:00         1211   \n",
      "8             Montreal  2023-06-16T17:30:00+00:00  -04:00:00         1212   \n",
      "9            Spielberg  2023-06-30T15:00:00+00:00   02:00:00         1213   \n",
      "10         Silverstone  2023-07-07T11:30:00+00:00   01:00:00         1214   \n",
      "11         Hungaroring  2023-07-21T11:30:00+00:00   02:00:00         1215   \n",
      "12   Spa-Francorchamps  2023-07-28T11:30:00+00:00   02:00:00         1216   \n",
      "13           Zandvoort  2023-08-25T10:30:00+00:00   02:00:00         1217   \n",
      "14               Monza  2023-09-01T11:30:00+00:00   02:00:00         1218   \n",
      "15           Singapore  2023-09-15T09:30:00+00:00   08:00:00         1219   \n",
      "16              Suzuka  2023-09-22T02:30:00+00:00   09:00:00         1220   \n",
      "17              Lusail  2023-10-06T13:30:00+00:00   03:00:00         1221   \n",
      "18              Austin  2023-10-20T17:30:00+00:00  -05:00:00         1222   \n",
      "19         Mexico City  2023-10-27T18:30:00+00:00  -06:00:00         1223   \n",
      "20          Interlagos  2023-11-03T14:30:00+00:00  -03:00:00         1224   \n",
      "21           Las Vegas  2023-11-17T04:30:00+00:00  -08:00:00         1225   \n",
      "22  Yas Marina Circuit  2023-11-24T09:30:00+00:00   04:00:00         1226   \n",
      "23              Sakhir  2024-02-29T11:30:00+00:00   03:00:00         1229   \n",
      "24              Jeddah  2024-03-07T13:30:00+00:00   03:00:00         1230   \n",
      "25           Melbourne  2024-03-22T01:30:00+00:00   11:00:00         1231   \n",
      "26              Suzuka  2024-04-05T02:30:00+00:00   09:00:00         1232   \n",
      "27            Shanghai  2024-04-19T03:30:00+00:00   08:00:00         1233   \n",
      "28               Miami  2024-05-03T16:30:00+00:00  -04:00:00         1234   \n",
      "29               Imola  2024-05-17T11:30:00+00:00   02:00:00         1235   \n",
      "30         Monte Carlo  2024-05-24T11:30:00+00:00   02:00:00         1236   \n",
      "31            Montreal  2024-06-07T17:30:00+00:00  -04:00:00         1237   \n",
      "32           Catalunya  2024-06-21T11:30:00+00:00   02:00:00         1238   \n",
      "33           Spielberg  2024-06-28T10:30:00+00:00   02:00:00         1239   \n",
      "34         Silverstone  2024-07-05T11:30:00+00:00   01:00:00         1240   \n",
      "35         Hungaroring  2024-07-19T11:30:00+00:00   02:00:00         1241   \n",
      "36   Spa-Francorchamps  2024-07-26T11:30:00+00:00   02:00:00         1242   \n",
      "37           Zandvoort  2024-08-23T10:30:00+00:00   02:00:00         1243   \n",
      "38               Monza  2024-08-30T11:30:00+00:00   02:00:00         1244   \n",
      "39                Baku  2024-09-13T09:30:00+00:00   04:00:00         1245   \n",
      "40           Singapore  2024-09-20T09:30:00+00:00   08:00:00         1246   \n",
      "41              Austin  2024-10-18T17:30:00+00:00  -05:00:00         1247   \n",
      "42         Mexico City  2024-10-25T18:30:00+00:00  -06:00:00         1248   \n",
      "43          Interlagos  2024-11-01T14:30:00+00:00  -03:00:00         1249   \n",
      "44           Las Vegas  2024-11-22T02:30:00+00:00  -08:00:00         1250   \n",
      "45              Lusail  2024-11-29T13:30:00+00:00   03:00:00         1251   \n",
      "46  Yas Marina Circuit  2024-12-06T09:30:00+00:00   04:00:00         1252   \n",
      "47              Sakhir  2025-02-26T07:00:00+00:00   03:00:00         1253   \n",
      "48           Melbourne  2025-03-14T01:30:00+00:00   11:00:00         1254   \n",
      "49            Shanghai  2025-03-21T03:30:00+00:00   08:00:00         1255   \n",
      "50              Suzuka  2025-04-04T02:30:00+00:00   09:00:00         1256   \n",
      "\n",
      "    year meeting_code  \n",
      "0   2023          NaN  \n",
      "1   2023          NaN  \n",
      "2   2023          NaN  \n",
      "3   2023          NaN  \n",
      "4   2023          NaN  \n",
      "5   2023          NaN  \n",
      "6   2023          NaN  \n",
      "7   2023          NaN  \n",
      "8   2023          NaN  \n",
      "9   2023          AUT  \n",
      "10  2023          NaN  \n",
      "11  2023          NaN  \n",
      "12  2023          NaN  \n",
      "13  2023          NaN  \n",
      "14  2023          NaN  \n",
      "15  2023          NaN  \n",
      "16  2023          NaN  \n",
      "17  2023          NaN  \n",
      "18  2023          NaN  \n",
      "19  2023          NaN  \n",
      "20  2023          NaN  \n",
      "21  2023          NaN  \n",
      "22  2023          NaN  \n",
      "23  2024          BRN  \n",
      "24  2024          KSA  \n",
      "25  2024          AUS  \n",
      "26  2024          JPN  \n",
      "27  2024          CHN  \n",
      "28  2024          USA  \n",
      "29  2024          ITA  \n",
      "30  2024          MON  \n",
      "31  2024          CAN  \n",
      "32  2024          ESP  \n",
      "33  2024          AUT  \n",
      "34  2024          GBR  \n",
      "35  2024          HUN  \n",
      "36  2024          BEL  \n",
      "37  2024          NED  \n",
      "38  2024          ITA  \n",
      "39  2024          AZE  \n",
      "40  2024          SGP  \n",
      "41  2024          USA  \n",
      "42  2024          MEX  \n",
      "43  2024          BRA  \n",
      "44  2024          USA  \n",
      "45  2024          QAT  \n",
      "46  2024          UAE  \n",
      "47  2025          BRN  \n",
      "48  2025          AUS  \n",
      "49  2025          CHN  \n",
      "50  2025          JPN  \n"
     ]
    }
   ],
   "source": [
    "query_meetings = query_base+\"meetings?year>2022\"\n",
    "\n",
    "response = urlopen(query_meetings)\n",
    "data = json.loads(response.read().decode('utf-8'))\n",
    "meetings_df = pd.json_normalize(data)\n",
    "\n",
    "print(meetings_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the race weekends have a different number of practice and qualifiying rounds. Some also have Stints in addition to the Grand prix. We are interested in just the race weekends that have 3 practice rounds and one qualifying round.\n",
    "\n",
    "From this, we got a dataframe of all the sessions with their correspnding meeting_key and the session type (practice, qualifying, or race)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     meeting_key  session_key session_type\n",
      "0           1141         7765     Practice\n",
      "1           1141         7766     Practice\n",
      "2           1141         7767     Practice\n",
      "3           1141         7768   Qualifying\n",
      "4           1141         7953         Race\n",
      "..           ...          ...          ...\n",
      "175         1256         9999     Practice\n",
      "176         1256        10000     Practice\n",
      "177         1256        10001     Practice\n",
      "178         1256        10002   Qualifying\n",
      "179         1256        10006         Race\n",
      "\n",
      "[180 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# convert meetings to a list\n",
    "meeting_list = meetings_df['meeting_key'].to_list()\n",
    "\n",
    "# create meeting session list\n",
    "valid_meeting_sessions = []\n",
    "\n",
    "# loop through each meeting\n",
    "for meeting in meeting_list:\n",
    "    query_sessions = query_base + \"sessions?meeting_key=\" + str(meeting)\n",
    "\n",
    "    response = urlopen(query_sessions)\n",
    "    data = json.loads(response.read().decode('utf-8'))\n",
    "    sessions_df = pd.json_normalize(data)\n",
    "    \n",
    "    # check for the 3 practice rounds, qualifier, and race\n",
    "    session_types = set(sessions_df['session_type'].unique())  # Get unique session types for the meeting\n",
    "\n",
    "    required_session_types = {'Practice', 'Qualifying', 'Race'}\n",
    "\n",
    "    # we need 3 Practice sessions, 1 Qualifying, and 1 Race\n",
    "    practice_sessions = [session for session in sessions_df['session_type'] if session == 'Practice']\n",
    "    qualifying_sessions = [session for session in sessions_df['session_type'] if session == 'Qualifying']\n",
    "    race_sessions = [session for session in sessions_df['session_type'] if session == 'Race']\n",
    "\n",
    "    # check if the meeting has exactly 3 practice sessions, 1 qualifying, and 1 race\n",
    "    if len(practice_sessions) == 3 and len(qualifying_sessions) == 1 and len(race_sessions) == 1:\n",
    "\n",
    "        # loop through the valid sessions and add to a list\n",
    "        for session in sessions_df.itertuples():\n",
    "            valid_meeting_sessions.append({\n",
    "                'meeting_key': meeting,\n",
    "                'session_key': session.session_key,\n",
    "                'session_type': session.session_type })\n",
    "            \n",
    "    # add sleep time to not overload requests\n",
    "    time.sleep(0.5)\n",
    "\n",
    "# convner to a DF \n",
    "valid_sessions_df = pd.DataFrame(valid_meeting_sessions)\n",
    "\n",
    "print(valid_sessions_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we sectioned off the Race sessions into their own data frame.\n",
    "\n",
    "We then turned the meeting_keys into a list to cycle through later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    meeting_key  session_key session_type\n",
      "4          1141         7953         Race\n",
      "9          1142         7779         Race\n",
      "14         1143         7787         Race\n",
      "19         1208         9078         Race\n",
      "24         1210         9094         Race\n",
      "36\n",
      "[1141, 1142, 1143, 1208, 1210, 1211, 1212, 1214, 1215, 1217, 1218, 1219, 1220, 1223, 1225, 1226, 1229, 1230, 1231, 1232, 1235, 1236, 1237, 1238, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1248, 1250, 1252, 1254, 1256]\n",
      "36\n"
     ]
    }
   ],
   "source": [
    "## create a data frame of all the session_keys that are the actual races\n",
    "# these will be used to get the label (final race position) later\n",
    "race_session_df = valid_sessions_df[valid_sessions_df['session_type']==\"Race\"]\n",
    "\n",
    "print(race_session_df.head())\n",
    "print(len(race_session_df))\n",
    "\n",
    "# now get the list of viable meetings to loop through\n",
    "valid_meeting_list = race_session_df['meeting_key'].to_list()\n",
    "\n",
    "print(valid_meeting_list)\n",
    "print(len(valid_meeting_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Racing Profile\n",
    "\n",
    "This block creates a function that when given a meeting_key will generate all the features for each driver in the Race. \n",
    "\n",
    "There are 82 features collected for each driver, 20 for each session, and then the driver's number and the meeting_key (to be used for merging later).\n",
    "\n",
    "The function returns a list of 20 lists, one for each driver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## loop through all the valid meeting keys\n",
    "def get_data(meeting):\n",
    "    # initalize list to appene data to\n",
    "    data_list = []  \n",
    "\n",
    "    # get session numbers for practice and qualifiying\n",
    "    query_sessions = query_base+\"sessions?meeting_key=\"+str(meeting)\n",
    "\n",
    "    response = urlopen(query_sessions)\n",
    "    data = json.loads(response.read().decode('utf-8'))\n",
    "    sessions_df = pd.json_normalize(data)\n",
    "\n",
    "    # get just the session keys \n",
    "    sessions = list(sessions_df['session_key'])\n",
    "    # get race session num\n",
    "    race_session_num = sessions[4]\n",
    "\n",
    "    # remove the real race\n",
    "    del sessions[-1]\n",
    "    # print(sessions)\n",
    "    # we will loop through the sessions later\n",
    "\n",
    "    ## query the drivers for each race session so that we know they raced in the grand prix\n",
    "    query_drivers = query_base+\"drivers?session_key=\"+str(race_session_num)\n",
    "\n",
    "    response = urlopen(query_drivers)\n",
    "    data = json.loads(response.read().decode('utf-8'))\n",
    "    drivers_df = pd.json_normalize(data)\n",
    "\n",
    "    # get all the driver numbers to loop through later\n",
    "    drivers = list(drivers_df['driver_number'])\n",
    "\n",
    "    # print(drivers)\n",
    "\n",
    "    # add sleep time to not overload requests\n",
    "    time.sleep(0.5)\n",
    "\n",
    "    ## Loop through the drivers\n",
    "    for driver in drivers:\n",
    "        # create list to hold the observation\n",
    "        driver_feats = [meeting, driver]\n",
    "\n",
    "        driver_number = str(driver)\n",
    "\n",
    "        ## Loop through all the sessions\n",
    "        for session in sessions:\n",
    "            # creat list to store all data for this session\n",
    "            session_feats = []\n",
    "\n",
    "            # LAPS QUERY\n",
    "            query_laps = query_base+\"laps?driver_number=\"+driver_number+\"&session_key=\"+str(session)\n",
    "\n",
    "            try:\n",
    "                # Call API and convert to DataFrame\n",
    "                response = urlopen(query_laps)\n",
    "                data = json.loads(response.read().decode('utf-8'))\n",
    "                laps_df = pd.json_normalize(data)\n",
    "                \n",
    "                # Check if the DataFrame is empty (no laps data returned)\n",
    "                if laps_df.empty:\n",
    "                    print(f\"No data returned for driver {driver} and session {session}. Skipping.\")\n",
    "                    continue  # Skip to the next session\n",
    "\n",
    "\n",
    "                # extract lap infor for current session\n",
    "                min_lap = laps_df['lap_duration'].min()\n",
    "                max_lap = laps_df['lap_duration'].max()\n",
    "                avg_lap = float(round(laps_df['lap_duration'].mean(),3))\n",
    "                num_laps = laps_df['lap_number'].max()\n",
    "\n",
    "                # PARSE THE LAPS DATA BY TIME\n",
    "                # laps_times_df will be used for car_data queries\n",
    "                lap_times = laps_df[['lap_number','date_start','lap_duration']].copy()\n",
    "\n",
    "                # strip the time zone since its the same for all sessions\n",
    "                lap_times['date_start'] = lap_times['date_start'].str.replace(r':\\+.*$', '', regex=True)\n",
    "\n",
    "                # Convert date_start to datetime if it's not already in datetime format\n",
    "                lap_times['date_start'] = pd.to_datetime(lap_times['date_start'], errors='coerce')\n",
    "\n",
    "                # use the next lap start as the end time exept for the last lap, which will be calculated with lap duration\n",
    "                lap_times['date_end'] = lap_times['date_start'].shift(-1).fillna(lap_times['date_start'] + pd.to_timedelta(lap_times['lap_duration'], unit='s'))\n",
    "\n",
    "                # convert back to string\n",
    "                lap_times['date_start'] = lap_times['date_start'].dt.strftime('%Y-%m-%dT%H:%M:%S.%f') + lap_times['date_start'].dt.strftime('%z').str[:3] + ':' + lap_times['date_start'].dt.strftime('%z').str[3:]\n",
    "                lap_times['date_end'] = lap_times['date_end'].dt.strftime('%Y-%m-%dT%H:%M:%S.%f') + lap_times['date_end'].dt.strftime('%z').str[:3] + ':' + lap_times['date_end'].dt.strftime('%z').str[3:]\n",
    "\n",
    "\n",
    "                # find the lap number for their best lap\n",
    "                min_lap_num = laps_df[laps_df['lap_duration']==min_lap]['lap_number'].to_list()[0]\n",
    "\n",
    "            except (HTTPError, URLError) as e:\n",
    "                # Handle the error if the API call fails\n",
    "                print(f\"Error occurred for driver {driver} and session {session}: {e}. Skipping this session.\")\n",
    "\n",
    "            # CONDUCT A CAR DATA QUERY ON THE MINIMUM LAP\n",
    "            # base car data query for time filter to be added to\n",
    "            query_car_base = query_base+\"car_data?driver_number=\"+driver_number+\"&session_key=\"+str(session)\n",
    "\n",
    "            # create staret and end time for car data query\n",
    "            start_time = lap_times[lap_times['lap_number']==min_lap_num]['date_start'].to_list()[0]\n",
    "            end_time = lap_times[lap_times['lap_number']==min_lap_num]['date_end'].to_list()[0]\n",
    "\n",
    "            # query for lap specific times\n",
    "            query_car = query_car_base + \"&date>=\"+str(start_time)+\"&date<=\"+str(end_time)\n",
    "\n",
    "            try:\n",
    "                # call api for car data with lap time query\n",
    "                response = urlopen(query_car)\n",
    "                data = json.loads(response.read().decode('utf-8'))\n",
    "                car_df = pd.json_normalize(data)\n",
    "                \n",
    "                # Check if the DataFrame is empty (no laps data returned)\n",
    "                if car_df.empty:\n",
    "                    print(f\"No data returned for driver {driver} and session {session}. Skipping.\")\n",
    "                    continue  # Skip to the next session\n",
    "\n",
    "                # get summary stats for the lap\n",
    "                max_brake = car_df['brake'].max()\n",
    "                max_rpm = car_df['rpm'].max()\n",
    "                min_rpm = car_df['rpm'].min()\n",
    "                avg_rpm = round(car_df['rpm'].mean())\n",
    "                max_throttle = car_df['throttle'].max()\n",
    "                avg_throttle = float(round(car_df['throttle'].mean()))\n",
    "                min_speed = car_df['speed'].min()\n",
    "                max_speed = car_df['speed'].max()\n",
    "                avg_speed = round(car_df['speed'].mean())\n",
    "\n",
    "                # create list of car_data stats per lap\n",
    "                min_lap_stats = [max_brake, min_rpm, max_rpm, avg_rpm, max_throttle, avg_throttle, min_speed, max_speed, avg_speed]\n",
    "\n",
    "            except (HTTPError, URLError) as e:\n",
    "                # Handle the error if the API call fails\n",
    "                print(f\"Error occurred for driver {driver} and session {session}: {e}. Skipping this session.\")\n",
    "\n",
    "            # STINTS QUERY FOR NUMBER OF STINTS\n",
    "            query_stints = query_base + \"stints?driver_number=\"+driver_number+\"&session_key=\"+str(session)\n",
    "\n",
    "            try:\n",
    "                # call api and convert to df\n",
    "                response = urlopen(query_stints)\n",
    "                data = json.loads(response.read().decode('utf-8'))\n",
    "                stints_df = pd.json_normalize(data)\n",
    "\n",
    "                if stints_df.empty:\n",
    "                    print(f\"No data returned for driver {driver} and session {session}. Skipping.\")\n",
    "                    continue  # Skip to the next session\n",
    "\n",
    "                # extract max stint number\n",
    "                num_stints = stints_df['stint_number'].max()\n",
    "\n",
    "            except (HTTPError, URLError) as e:\n",
    "                # Handle the error if the API call fails\n",
    "                print(f\"Error occurred for driver {driver} and session {session}: {e}. Skipping this session.\")\n",
    "\n",
    "\n",
    "            # PTIS QUERY\n",
    "            query_pits = query_base + \"pit?driver_number=\"+driver_number+\"&session_key=\"+str(session)\n",
    "\n",
    "            try:\n",
    "                # call api and convert to df\n",
    "                response = urlopen(query_pits)\n",
    "                data = json.loads(response.read().decode('utf-8'))\n",
    "                pits_df = pd.json_normalize(data)\n",
    "\n",
    "                if pits_df.empty:\n",
    "                    print(f\"No data returned for driver {driver} and session {session}. Skipping.\")\n",
    "                    continue  # Skip to the next session\n",
    "\n",
    "                # extract num of pits and avg pit duration\n",
    "                num_pits = len(pits_df)\n",
    "                avg_pit_time = float(round(pits_df['pit_duration'].mean(),1))\n",
    "\n",
    "            except (HTTPError, URLError) as e:\n",
    "                # Handle the error if the API call fails\n",
    "                print(f\"Error occurred for driver {driver} and session {session}: {e}. Skipping this session.\")\n",
    "\n",
    "            # WEATHER QUERY\n",
    "            query_wx = query_base + \"weather?&session_key=\"+str(session)\n",
    "\n",
    "            try:\n",
    "                # call api and convert to df\n",
    "                response = urlopen(query_wx)\n",
    "                data = json.loads(response.read().decode('utf-8'))\n",
    "                weather_df = pd.json_normalize(data)\n",
    "\n",
    "                if weather_df.empty:\n",
    "                    print(f\"No data returned for driver {driver} and session {session}. Skipping.\")\n",
    "                    continue  # Skip to the next session\n",
    "\n",
    "                ### parse weather data\n",
    "                did_rain = weather_df['rainfall'].max()\n",
    "                max_wind = weather_df['wind_speed'].max()\n",
    "                avg_air_temp = float(round(weather_df['air_temperature'].mean(),3))\n",
    "                avg_track_temp = float(round(weather_df['track_temperature'].mean(),3))\n",
    "\n",
    "                wx_stats = [did_rain, max_wind, avg_air_temp, avg_track_temp]\n",
    "\n",
    "            except (HTTPError, URLError) as e:\n",
    "                # Handle the error if the API call fails\n",
    "                print(f\"Error occurred for driver {driver} and session {session}: {e}. Skipping this session.\")\n",
    "\n",
    "            # AFTER ALL QUERIES PER SESSION\n",
    "            # append to driver features list\n",
    "            session_feats = [min_lap, max_lap, avg_lap, num_laps, num_stints] + [num_pits, avg_pit_time] + wx_stats + min_lap_stats \n",
    "\n",
    "            driver_feats.extend(session_feats)\n",
    "        \n",
    "        # print(driver_feats)\n",
    "        data_list.append(driver_feats)\n",
    "        # add sleep time to not overload requests\n",
    "        time.sleep(2)\n",
    "    return data_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the column names for the dataframe and a function to enforce the time it takes per meeting_key.\n",
    "\n",
    "Note: I used ChatGPT for the timeout function and for help on the try/except loops for error handling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = ['meeting_key', 'driver_num',\n",
    "            'min_lap_p1', 'max_lap_p1', 'avg_lap_p1', 'num_laps_p1', 'num_stints_p1', 'num_pits_p1', 'avg_pit_time_p1',\n",
    "           'max_brake_p1', 'min_rpm_p1', 'max_rpm_p1', 'avg_rpm_p1', 'max_throttle_p1', 'avg_throttle_p1', 'min_speed_p1',\n",
    "           'max_speed_p1', 'avg_speed_p1', 'did_rain_p1', 'max_wind_p1', 'avg_air_temp_p1', 'avg_track_temp_p1',\n",
    "           'min_lap_p2', 'max_lap_p2', 'avg_lap_p2', 'num_laps_p2', 'num_stints_p2', 'num_pits_p2', 'avg_pit_time_p2',\n",
    "           'max_brake_p2', 'min_rpm_p2', 'max_rpm_p2', 'avg_rpm_p2', 'max_throttle_p2', 'avg_throttle_p2', 'min_speed_p2',\n",
    "           'max_speed_p2', 'avg_speed_p2', 'did_rain_p2', 'max_wind_p2', 'avg_air_temp_p2', 'avg_track_temp_p2',\n",
    "           'min_lap_p3', 'max_lap_p3', 'avg_lap_p3', 'num_laps_p3', 'num_stints_p3', 'num_pits_p3', 'avg_pit_time_p3',\n",
    "           'max_brake_p3', 'min_rpm_p3', 'max_rpm_p3', 'avg_rpm_p3', 'max_throttle_p3', 'avg_throttle_p3', 'min_speed_p3',\n",
    "           'max_speed_p3', 'avg_speed_p3','did_rain_p3', 'max_wind_p3', 'avg_air_temp_p3', 'avg_track_temp_p3', \n",
    "           'min_lap_q', 'max_lap_q', 'avg_lap_q', 'num_laps_q', 'num_stints_q','num_pits_q', 'avg_pit_time_q',\n",
    "           'max_brake_q', 'min_rpm_q', 'max_rpm_q', 'avg_rpm_q', 'max_throttle_q', 'avg_throttle_q', 'min_speed_q', \n",
    "           'max_speed_q', 'avg_speed_q','did_rain_q', 'max_wind_q', 'avg_air_temp_q', 'avg_track_temp_q']\n",
    "\n",
    "# Function to handle the timeout\n",
    "def handler(signum, frame):\n",
    "    raise TimeoutError(\"Timeout exceeded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collecting Data\n",
    "\n",
    "This block loops through the valid meeting_keys, calls the function, converts the returned list to a dataframe, and then saves the dataframe as a csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data returned for driver 1 and session 7765. Skipping.\n",
      "No data returned for driver 1 and session 7766. Skipping.\n",
      "No data returned for driver 1 and session 7767. Skipping.\n",
      "No data returned for driver 1 and session 7768. Skipping.\n",
      "No data returned for driver 2 and session 7765. Skipping.\n",
      "No data returned for driver 2 and session 7766. Skipping.\n",
      "No data returned for driver 2 and session 7767. Skipping.\n",
      "No data returned for driver 2 and session 7768. Skipping.\n",
      "No data returned for driver 4 and session 7765. Skipping.\n",
      "No data returned for driver 4 and session 7766. Skipping.\n",
      "No data returned for driver 4 and session 7767. Skipping.\n",
      "No data returned for driver 4 and session 7768. Skipping.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[163], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m signal\u001b[38;5;241m.\u001b[39malarm(timeout)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Attempt to get the data\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m d_list \u001b[38;5;241m=\u001b[39m \u001b[43mget_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmeeting_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(d_list, columns\u001b[38;5;241m=\u001b[39mcolnames)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Reset the timer (if successful)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[151], line 212\u001b[0m, in \u001b[0;36mget_data\u001b[0;34m(meeting)\u001b[0m\n\u001b[1;32m    210\u001b[0m     data_list\u001b[38;5;241m.\u001b[39mappend(driver_feats)\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;66;03m# add sleep time to not overload requests\u001b[39;00m\n\u001b[0;32m--> 212\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data_list\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sub_valid_meeting_list = valid_meeting_list[0:16]\n",
    "\n",
    "# Setting up the signal handler\n",
    "signal.signal(signal.SIGALRM, handler)\n",
    "\n",
    "# Define timeout (in seconds)\n",
    "timeout = 300\n",
    "\n",
    "for meeting_key in sub_valid_meeting_list:\n",
    "    try:\n",
    "        # Start the timer\n",
    "        signal.alarm(timeout)\n",
    "        \n",
    "        # Attempt to get the data\n",
    "        d_list = get_data(meeting_key)\n",
    "        df = pd.DataFrame(d_list, columns=colnames)\n",
    "\n",
    "        # Reset the timer (if successful)\n",
    "        signal.alarm(0)\n",
    "\n",
    "        # Save the data to CSV\n",
    "        file_name = f'data/racing_profiles_{meeting_key}.csv'\n",
    "        df.to_csv(file_name, index=False)\n",
    "\n",
    "        print(f\"Saved file for meeting_key {meeting_key}\")\n",
    "\n",
    "    except TimeoutError:\n",
    "        print(f\"Timeout occurred for meeting_key {meeting_key}, skipping.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred for meeting_key {meeting_key}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the initial run, some of the meetings did not get saved:\n",
    "1232, 1240, 1242, 1243, 1246, 1250, 1254\n",
    "\n",
    "I will try and go back and do those individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data returned for driver 1 and session 9489. Skipping.\n",
      "No data returned for driver 1 and session 9490. Skipping.\n",
      "No data returned for driver 2 and session 9489. Skipping.\n",
      "No data returned for driver 2 and session 9490. Skipping.\n",
      "No data returned for driver 3 and session 9489. Skipping.\n",
      "No data returned for driver 4 and session 9489. Skipping.\n",
      "No data returned for driver 10 and session 9489. Skipping.\n",
      "No data returned for driver 10 and session 9490. Skipping.\n",
      "No data returned for driver 11 and session 9489. Skipping.\n",
      "No data returned for driver 11 and session 9490. Skipping.\n",
      "No data returned for driver 14 and session 9489. Skipping.\n",
      "No data returned for driver 14 and session 9490. Skipping.\n",
      "No data returned for driver 16 and session 9489. Skipping.\n",
      "No data returned for driver 18 and session 9489. Skipping.\n",
      "No data returned for driver 18 and session 9490. Skipping.\n",
      "No data returned for driver 20 and session 9489. Skipping.\n",
      "No data returned for driver 22 and session 9489. Skipping.\n",
      "No data returned for driver 23 and session 9489. Skipping.\n",
      "No data returned for driver 24 and session 9489. Skipping.\n",
      "No data returned for driver 27 and session 9489. Skipping.\n",
      "No data returned for driver 31 and session 9489. Skipping.\n",
      "No data returned for driver 44 and session 9489. Skipping.\n",
      "No data returned for driver 55 and session 9489. Skipping.\n",
      "No data returned for driver 63 and session 9489. Skipping.\n",
      "No data returned for driver 63 and session 9490. Skipping.\n",
      "No data returned for driver 77 and session 9489. Skipping.\n",
      "No data returned for driver 81 and session 9489. Skipping.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "82 columns passed, passed data had 62 columns",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/dsan5300/lib/python3.13/site-packages/pandas/core/internals/construction.py:939\u001b[0m, in \u001b[0;36m_finalize_columns_and_data\u001b[0;34m(content, columns, dtype)\u001b[0m\n\u001b[1;32m    938\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 939\u001b[0m     columns \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_or_indexify_columns\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    940\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    941\u001b[0m     \u001b[38;5;66;03m# GH#26429 do not raise user-facing AssertionError\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dsan5300/lib/python3.13/site-packages/pandas/core/internals/construction.py:986\u001b[0m, in \u001b[0;36m_validate_or_indexify_columns\u001b[0;34m(content, columns)\u001b[0m\n\u001b[1;32m    984\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_mi_list \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(columns) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(content):  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[1;32m    985\u001b[0m     \u001b[38;5;66;03m# caller's responsibility to check for this...\u001b[39;00m\n\u001b[0;32m--> 986\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m    987\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(columns)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m columns passed, passed data had \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    988\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(content)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m columns\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    989\u001b[0m     )\n\u001b[1;32m    990\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_mi_list:\n\u001b[1;32m    991\u001b[0m     \u001b[38;5;66;03m# check if nested list column, length of each sub-list should be equal\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: 82 columns passed, passed data had 62 columns",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[153], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# run the function\u001b[39;00m\n\u001b[1;32m      6\u001b[0m d_list \u001b[38;5;241m=\u001b[39m get_data(meeting_key)\n\u001b[0;32m----> 7\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43md_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolnames\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Save the data to CSV\u001b[39;00m\n\u001b[1;32m     10\u001b[0m file_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/racing_profiles_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmeeting_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/dsan5300/lib/python3.13/site-packages/pandas/core/frame.py:851\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    849\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    850\u001b[0m         columns \u001b[38;5;241m=\u001b[39m ensure_index(columns)\n\u001b[0;32m--> 851\u001b[0m     arrays, columns, index \u001b[38;5;241m=\u001b[39m \u001b[43mnested_data_to_arrays\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# error: Argument 3 to \"nested_data_to_arrays\" has incompatible\u001b[39;49;00m\n\u001b[1;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# type \"Optional[Collection[Any]]\"; expected \"Optional[Index]\"\u001b[39;49;00m\n\u001b[1;32m    854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m    857\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    859\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m arrays_to_mgr(\n\u001b[1;32m    860\u001b[0m         arrays,\n\u001b[1;32m    861\u001b[0m         columns,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    864\u001b[0m         typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[1;32m    865\u001b[0m     )\n\u001b[1;32m    866\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/dsan5300/lib/python3.13/site-packages/pandas/core/internals/construction.py:520\u001b[0m, in \u001b[0;36mnested_data_to_arrays\u001b[0;34m(data, columns, index, dtype)\u001b[0m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_named_tuple(data[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;129;01mand\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    518\u001b[0m     columns \u001b[38;5;241m=\u001b[39m ensure_index(data[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_fields)\n\u001b[0;32m--> 520\u001b[0m arrays, columns \u001b[38;5;241m=\u001b[39m \u001b[43mto_arrays\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    521\u001b[0m columns \u001b[38;5;241m=\u001b[39m ensure_index(columns)\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/dsan5300/lib/python3.13/site-packages/pandas/core/internals/construction.py:845\u001b[0m, in \u001b[0;36mto_arrays\u001b[0;34m(data, columns, dtype)\u001b[0m\n\u001b[1;32m    842\u001b[0m     data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mtuple\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m data]\n\u001b[1;32m    843\u001b[0m     arr \u001b[38;5;241m=\u001b[39m _list_to_arrays(data)\n\u001b[0;32m--> 845\u001b[0m content, columns \u001b[38;5;241m=\u001b[39m \u001b[43m_finalize_columns_and_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m content, columns\n",
      "File \u001b[0;32m~/miniconda3/envs/dsan5300/lib/python3.13/site-packages/pandas/core/internals/construction.py:942\u001b[0m, in \u001b[0;36m_finalize_columns_and_data\u001b[0;34m(content, columns, dtype)\u001b[0m\n\u001b[1;32m    939\u001b[0m     columns \u001b[38;5;241m=\u001b[39m _validate_or_indexify_columns(contents, columns)\n\u001b[1;32m    940\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    941\u001b[0m     \u001b[38;5;66;03m# GH#26429 do not raise user-facing AssertionError\u001b[39;00m\n\u001b[0;32m--> 942\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(err) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    944\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(contents) \u001b[38;5;129;01mand\u001b[39;00m contents[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mobject_:\n\u001b[1;32m    945\u001b[0m     contents \u001b[38;5;241m=\u001b[39m convert_object_array(contents, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "\u001b[0;31mValueError\u001b[0m: 82 columns passed, passed data had 62 columns"
     ]
    }
   ],
   "source": [
    "## For Meeting 1232\n",
    "\n",
    "meeting_key = 1232\n",
    "\n",
    "# run the function\n",
    "d_list = get_data(meeting_key)\n",
    "df = pd.DataFrame(d_list, columns=colnames)\n",
    "\n",
    "# Save the data to CSV\n",
    "file_name = f'data/racing_profiles_{meeting_key}.csv'\n",
    "df.to_csv(file_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indiviudal Driver Profile\n",
    "\n",
    "Loop to create an individual driver observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'pit_duration'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[164], line 104\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;66;03m# extract num of pits and avg pit duration\u001b[39;00m\n\u001b[1;32m    103\u001b[0m num_pits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(pits_df)\n\u001b[0;32m--> 104\u001b[0m avg_pit_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;28mround\u001b[39m(\u001b[43mpits_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpit_duration\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mmean(),\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m    106\u001b[0m \u001b[38;5;66;03m# WEATHER QUERY\u001b[39;00m\n\u001b[1;32m    107\u001b[0m query_wx \u001b[38;5;241m=\u001b[39m query_base \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweather?&session_key=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(session)\n",
      "File \u001b[0;32m~/miniconda3/envs/dsan5300/lib/python3.13/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/miniconda3/envs/dsan5300/lib/python3.13/site-packages/pandas/core/indexes/range.py:417\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[0;32m--> 417\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'pit_duration'"
     ]
    }
   ],
   "source": [
    "# set the driver number\n",
    "driver_number = str(1)\n",
    "\n",
    "# create list of features for a individual driver\n",
    "driver_feats = [driver_number]\n",
    "\n",
    "# list of sessions\n",
    "session_sub = [7765]\n",
    "\n",
    "\n",
    "for session in session_sub:\n",
    "    # creat list to store all data for this session\n",
    "    session_feats = []\n",
    "\n",
    "    # LAPS QUERY\n",
    "    query_laps = query_base+\"laps?driver_number=\"+driver_number+\"&session_key=\"+str(session)\n",
    "\n",
    "    # call api and convert to df\n",
    "    response = urlopen(query_laps)\n",
    "    data = json.loads(response.read().decode('utf-8'))\n",
    "    laps_df = pd.json_normalize(data)\n",
    "\n",
    "    # extract lap infor for current session\n",
    "    min_lap = laps_df['lap_duration'].min()\n",
    "    max_lap = laps_df['lap_duration'].max()\n",
    "    avg_lap = float(round(laps_df['lap_duration'].mean(),3))\n",
    "    num_laps = laps_df['lap_number'].max()\n",
    "\n",
    "    # PARSE THE LAPS DATA BY TIME\n",
    "    # laps_times_df will be used for car_data queries\n",
    "    lap_times = laps_df[['lap_number','date_start','lap_duration']].copy()\n",
    "\n",
    "    # strip the time zone since its the same for all sessions\n",
    "    lap_times['date_start'] = lap_times['date_start'].str.replace(r':\\+.*$', '', regex=True)\n",
    "\n",
    "    # Convert date_start to datetime if it's not already in datetime format\n",
    "    lap_times['date_start'] = pd.to_datetime(lap_times['date_start'], errors='coerce')\n",
    "\n",
    "    # use the next lap start as the end time exept for the last lap, which will be calculated with lap duration\n",
    "    lap_times['date_end'] = lap_times['date_start'].shift(-1).fillna(lap_times['date_start'] + pd.to_timedelta(lap_times['lap_duration'], unit='s'))\n",
    "\n",
    "    # convert back to string\n",
    "    lap_times['date_start'] = lap_times['date_start'].dt.strftime('%Y-%m-%dT%H:%M:%S.%f') + lap_times['date_start'].dt.strftime('%z').str[:3] + ':' + lap_times['date_start'].dt.strftime('%z').str[3:]\n",
    "    lap_times['date_end'] = lap_times['date_end'].dt.strftime('%Y-%m-%dT%H:%M:%S.%f') + lap_times['date_end'].dt.strftime('%z').str[:3] + ':' + lap_times['date_end'].dt.strftime('%z').str[3:]\n",
    "\n",
    "\n",
    "    # find the lap number for their best lap\n",
    "    min_lap_num = laps_df[laps_df['lap_duration']==min_lap]['lap_number'].to_list()[0]\n",
    "\n",
    "    # CONDUCT A CAR DATA QUERY ON THE MINIMUM LAP\n",
    "    # base car data query for time filter to be added to\n",
    "    query_car_base = query_base+\"car_data?driver_number=\"+driver_number+\"&session_key=\"+str(session)\n",
    "\n",
    "    # create staret and end time for car data query\n",
    "    start_time = lap_times[lap_times['lap_number']==min_lap_num]['date_start'].to_list()[0]\n",
    "    end_time = lap_times[lap_times['lap_number']==min_lap_num]['date_end'].to_list()[0]\n",
    "\n",
    "    # query for lap specific times\n",
    "    query_car = query_car_base + \"&date>=\"+str(start_time)+\"&date<=\"+str(end_time)\n",
    "\n",
    "    # call api for car data with lap time query\n",
    "    response = urlopen(query_car)\n",
    "    data = json.loads(response.read().decode('utf-8'))\n",
    "    car_df = pd.json_normalize(data)\n",
    "\n",
    "\n",
    "    # get summary stats for the lap\n",
    "    max_brake = car_df['brake'].max()\n",
    "    max_rpm = car_df['rpm'].max()\n",
    "    min_rpm = car_df['rpm'].min()\n",
    "    avg_rpm = round(car_df['rpm'].mean())\n",
    "    max_throttle = car_df['throttle'].max()\n",
    "    avg_throttle = float(round(car_df['throttle'].mean()))\n",
    "    min_speed = car_df['speed'].min()\n",
    "    max_speed = car_df['speed'].max()\n",
    "    avg_speed = round(car_df['speed'].mean())\n",
    "\n",
    "    # create list of car_data stats per lap\n",
    "    min_lap_stats = [max_brake, min_rpm, max_rpm, avg_rpm, max_throttle, avg_throttle, min_speed, max_speed, avg_speed]\n",
    "\n",
    "\n",
    "    # STINTS QUERY FOR NUMBER OF STINTS\n",
    "    query_stints = query_base + \"stints?driver_number=\"+driver_number+\"&session_key=\"+str(session)\n",
    "\n",
    "    # call api and convert to df\n",
    "    response = urlopen(query_stints)\n",
    "    data = json.loads(response.read().decode('utf-8'))\n",
    "    stints_df = pd.json_normalize(data)\n",
    "\n",
    "    # extract max stint number\n",
    "    num_stints = stints_df['stint_number'].max()\n",
    "\n",
    "\n",
    "    # PTIS QUERY\n",
    "    query_pits = query_base + \"pit?driver_number=\"+driver_number+\"&session_key=\"+str(session)\n",
    "\n",
    "    # call api and convert to df\n",
    "    response = urlopen(query_pits)\n",
    "    data = json.loads(response.read().decode('utf-8'))\n",
    "    pits_df = pd.json_normalize(data)\n",
    "\n",
    "    # extract num of pits and avg pit duration\n",
    "    num_pits = len(pits_df)\n",
    "    avg_pit_time = float(round(pits_df['pit_duration'].mean(),1))\n",
    "\n",
    "    # WEATHER QUERY\n",
    "    query_wx = query_base + \"weather?&session_key=\"+str(session)\n",
    "\n",
    "    # call api and convert to df\n",
    "    response = urlopen(query_wx)\n",
    "    data = json.loads(response.read().decode('utf-8'))\n",
    "    weather_df = pd.json_normalize(data)\n",
    "\n",
    "    ### parse weather data\n",
    "\n",
    "    did_rain = weather_df['rainfall'].max()\n",
    "    max_wind = weather_df['wind_speed'].max()\n",
    "    avg_air_temp = float(round(weather_df['air_temperature'].mean(),3))\n",
    "    avg_track_temp = float(round(weather_df['track_temperature'].mean(),3))\n",
    "\n",
    "    wx_stats = [did_rain, max_wind, avg_air_temp, avg_track_temp]\n",
    "\n",
    "    # AFTER ALL QUERIES PER SESSION\n",
    "    # append to driver features list\n",
    "    session_feats = [min_lap, max_lap, avg_lap, num_laps, num_stints] + [num_pits, avg_pit_time] + wx_stats + min_lap_stats \n",
    "\n",
    "    driver_feats.extend(session_feats)\n",
    "\n",
    "\n",
    "\n",
    "print(driver_feats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['16', 90.03, 832.062, 162.989, 24, 4, 4, 370.5, 0, 6.8, 26.058, 35.126, 100, 7509, 11950, 10832, 100, 81.0, 84, 329, 241, 89.18, 712.401, 155.104, 25, 5, 5, 271.7, 0, 4.1, 25.371, 30.597, 100, 6701, 12149, 10848, 100, 81.0, 87, 331, 247, 88.608, 982.957, 207.677, 16, 4, 4, 719.1, 0, 5.8, 25.984, 39.559, 100, 6715, 12238, 10921, 100, 82.0, 92, 335, 250, 87.791, 636.95, 179.428, 23, 6, 6, 422.9, 0, 2.9, 25.106, 30.786, 100, 6750, 12228, 10902, 100, 83.0, 89, 330, 250]\n"
     ]
    }
   ],
   "source": [
    "# set the driver number\n",
    "driver_number = str(16)\n",
    "\n",
    "# create list of features for a individual driver\n",
    "driver_feats = [driver_number]\n",
    "\n",
    "# list of sessions\n",
    "session_sub = [9473, 9474, 9475, 9476]\n",
    "\n",
    "\n",
    "for session in session_sub:\n",
    "    # creat list to store all data for this session\n",
    "    session_feats = []\n",
    "\n",
    "    # LAPS QUERY\n",
    "    query_laps = query_base+\"laps?driver_number=\"+driver_number+\"&session_key=\"+str(session)\n",
    "\n",
    "    # call api and convert to df\n",
    "    response = urlopen(query_laps)\n",
    "    data = json.loads(response.read().decode('utf-8'))\n",
    "    laps_df = pd.json_normalize(data)\n",
    "\n",
    "    # extract lap infor for current session\n",
    "    min_lap = laps_df['lap_duration'].min()\n",
    "    max_lap = laps_df['lap_duration'].max()\n",
    "    avg_lap = float(round(laps_df['lap_duration'].mean(),3))\n",
    "    num_laps = laps_df['lap_number'].max()\n",
    "\n",
    "    # PARSE THE LAPS DATA BY TIME\n",
    "    # laps_times_df will be used for car_data queries\n",
    "    lap_times = laps_df[['lap_number','date_start','lap_duration']].copy()\n",
    "\n",
    "    # strip the time zone since its the same for all sessions\n",
    "    lap_times['date_start'] = lap_times['date_start'].str.replace(r':\\+.*$', '', regex=True)\n",
    "\n",
    "    # Convert date_start to datetime if it's not already in datetime format\n",
    "    lap_times['date_start'] = pd.to_datetime(lap_times['date_start'], errors='coerce')\n",
    "\n",
    "    # use the next lap start as the end time exept for the last lap, which will be calculated with lap duration\n",
    "    lap_times['date_end'] = lap_times['date_start'].shift(-1).fillna(lap_times['date_start'] + pd.to_timedelta(lap_times['lap_duration'], unit='s'))\n",
    "\n",
    "    # convert back to string\n",
    "    lap_times['date_start'] = lap_times['date_start'].dt.strftime('%Y-%m-%dT%H:%M:%S.%f') + lap_times['date_start'].dt.strftime('%z').str[:3] + ':' + lap_times['date_start'].dt.strftime('%z').str[3:]\n",
    "    lap_times['date_end'] = lap_times['date_end'].dt.strftime('%Y-%m-%dT%H:%M:%S.%f') + lap_times['date_end'].dt.strftime('%z').str[:3] + ':' + lap_times['date_end'].dt.strftime('%z').str[3:]\n",
    "\n",
    "\n",
    "    # find the lap number for their best lap\n",
    "    min_lap_num = laps_df[laps_df['lap_duration']==min_lap]['lap_number'].to_list()[0]\n",
    "\n",
    "    # CONDUCT A CAR DATA QUERY ON THE MINIMUM LAP\n",
    "    # base car data query for time filter to be added to\n",
    "    query_car_base = query_base+\"car_data?driver_number=\"+driver_number+\"&session_key=\"+str(session)\n",
    "\n",
    "    # create staret and end time for car data query\n",
    "    start_time = lap_times[lap_times['lap_number']==min_lap_num]['date_start'].to_list()[0]\n",
    "    end_time = lap_times[lap_times['lap_number']==min_lap_num]['date_end'].to_list()[0]\n",
    "\n",
    "    # query for lap specific times\n",
    "    query_car = query_car_base + \"&date>=\"+str(start_time)+\"&date<=\"+str(end_time)\n",
    "\n",
    "    # call api for car data with lap time query\n",
    "    response = urlopen(query_car)\n",
    "    data = json.loads(response.read().decode('utf-8'))\n",
    "    car_df = pd.json_normalize(data)\n",
    "\n",
    "\n",
    "    # get summary stats for the lap\n",
    "    max_brake = car_df['brake'].max()\n",
    "    max_rpm = car_df['rpm'].max()\n",
    "    min_rpm = car_df['rpm'].min()\n",
    "    avg_rpm = round(car_df['rpm'].mean())\n",
    "    max_throttle = car_df['throttle'].max()\n",
    "    avg_throttle = float(round(car_df['throttle'].mean()))\n",
    "    min_speed = car_df['speed'].min()\n",
    "    max_speed = car_df['speed'].max()\n",
    "    avg_speed = round(car_df['speed'].mean())\n",
    "\n",
    "    # create list of car_data stats per lap\n",
    "    min_lap_stats = [max_brake, min_rpm, max_rpm, avg_rpm, max_throttle, avg_throttle, min_speed, max_speed, avg_speed]\n",
    "\n",
    "\n",
    "    # STINTS QUERY FOR NUMBER OF STINTS\n",
    "    query_stints = query_base + \"stints?driver_number=\"+driver_number+\"&session_key=\"+str(session)\n",
    "\n",
    "    # call api and convert to df\n",
    "    response = urlopen(query_stints)\n",
    "    data = json.loads(response.read().decode('utf-8'))\n",
    "    stints_df = pd.json_normalize(data)\n",
    "\n",
    "    # extract max stint number\n",
    "    num_stints = stints_df['stint_number'].max()\n",
    "\n",
    "\n",
    "    # PTIS QUERY\n",
    "    query_pits = query_base + \"pit?driver_number=\"+driver_number+\"&session_key=\"+str(session)\n",
    "\n",
    "    # call api and convert to df\n",
    "    response = urlopen(query_pits)\n",
    "    data = json.loads(response.read().decode('utf-8'))\n",
    "    pits_df = pd.json_normalize(data)\n",
    "\n",
    "    # extract num of pits and avg pit duration\n",
    "    num_pits = len(pits_df)\n",
    "    avg_pit_time = float(round(pits_df['pit_duration'].mean(),1))\n",
    "\n",
    "    # WEATHER QUERY\n",
    "    query_wx = query_base + \"weather?&session_key=\"+str(session)\n",
    "\n",
    "    # call api and convert to df\n",
    "    response = urlopen(query_wx)\n",
    "    data = json.loads(response.read().decode('utf-8'))\n",
    "    weather_df = pd.json_normalize(data)\n",
    "\n",
    "    ### parse weather data\n",
    "\n",
    "    did_rain = weather_df['rainfall'].max()\n",
    "    max_wind = weather_df['wind_speed'].max()\n",
    "    avg_air_temp = float(round(weather_df['air_temperature'].mean(),3))\n",
    "    avg_track_temp = float(round(weather_df['track_temperature'].mean(),3))\n",
    "\n",
    "    wx_stats = [did_rain, max_wind, avg_air_temp, avg_track_temp]\n",
    "\n",
    "    # AFTER ALL QUERIES PER SESSION\n",
    "    # append to driver features list\n",
    "    session_feats = [min_lap, max_lap, avg_lap, num_laps, num_stints] + [num_pits, avg_pit_time] + wx_stats + min_lap_stats \n",
    "\n",
    "    driver_feats.extend(session_feats)\n",
    "\n",
    "\n",
    "\n",
    "print(driver_feats)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsan5300",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
